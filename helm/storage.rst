*******************
Configuring Storage
*******************


This document summarises how storage is configured for the HPCC platform.  It is easy to define simple configurations, but you have full control if required.  The system supports different classes of file storage, since each of these classes may need different performance characteristics.  The storage can be configured for each of the following classes:

- data
 
  The location that data files generated by OUTPUT/BUILD statements are found.  Any file that is persisted in the DFS.  Speed is likely to be important, but storage costs will also be significant.  Different types of data may have different characteristics.
  should this also include imports/land zones?  Probably.

- dlls

  Each ECL work unit compiled by the system generates a dll/so used by the engines to execute the query.  Performance is less of an issue since the workunit tends to be read infrequently.

- dali

  Dali is the data store that store meta information about files, workunits, and the state of the system.  This configures the location of the meta information.  Redundancy and speed are likely to be important.

- spill

  When processing complex queries all the data many not fit into memory.  This option configures where the data can be temporarily spilled to.  It is likely to be local, ephemeral and fast.

Each class of storage has an entry within the storage section of the Helm chart.  E.g. information about data is configured in storage.dataStorage, dali in daliStorage etc.

There are three different ways of configuring the storage with different levels of complexity:

Use the defaults
----------------

The default Helm chart creates temporary persistent volume claims for each of the sources of data.  The data disappears when the cluster is brought down.  The requirements can be configured in a couple of different ways:

  - storageSize: The capacity required for this particular type of storage.
  - storageClass: This provides some control over where the data is stored.

This mode is useful for experimenting with the system, or providing a consistent development environment.

Configure persistent volume claims (pvcs)
-----------------------------------------

This option allows you to use pvcs created independently of deploying the hpcc Helm chart.  This allows the data to be have a longer lifetime than hpcc cluster - so the cluster can be brought down when it is not in use, and the hpcc cluster can be upgraded to a new version, but the data is preserved.

The pre-existing pvc is specified by setting a value for ``storage.<class>Storage.pvc`` key, e.g. ``--set storage.daliStorage.pvc = my-nvme-pvc``, or::

  storage:
    daliStorage:
       pvc: my-nbme-pvc
    
There are several examples in the examples directory that demonstrate how to use pvcs to access data on a local host, and azure or aws storage.  

Storage planes
--------------

This provides full control over how and where the data is stored.  Any number of storage planes can be defined in the storage.planes section of the Helm chart.  A definition of a storage plane has the following structure:

planes:
  name: The name of this storage plane.

  prefix: For locally mounted file systems this is the path to the local mount.  For file systems accessed via a protocol/url this is the url prefix.

  pvc: What pvc is used to access this data.  If supplied the pvc will be mounted in each component that is required to access the data.  (The option is not specified for blob storage accessed via a url.)

  secret: If a secret is required to access the storage (e.g. an access token), the name of the entry in the secrets section of the helm chart.  (Not the k8s secret name.)

  numDevices: The number of logical storage devices.  An advanced option.  This allows data to be striped over multiple storage locations.  If it is set, then it assumes pvc defines a set of pvcs: ``pvc-1`` .. ``pvc-<n>``, which are mounted at locations ``prefix/d1`` .. ``prefix/d<n>``.  

  replication: Not normally set, but if specified data will be copied in the background to each of the storage planes in the list.

The planes are used by refering to them in the plane tag in the appropriate storage section.  E.g. ``--set storage.daliStorage.plane=dali-plane``.  If no plane is referenced for a storage class the simpler configuration will be used for that class.

By default the different engines - thor, roxie, eclagent write their data to the default data storage plane.  This can be overridden by defining the plane key within the component.  The spill location can be set through the spillPlane option.  It is also possible to override the target storage plane by using the CLUSTER options in the ECL language.  This allows the ECL programmer to write data to different storage planes depending on the performance/cost requirements.  The engines can read data from any of the data planes.
(Currently we use cluster to mean which set of machines to run a query on, and where the data is stored.  We probably need to separate those with a new attribute STORE(?) .)

A plane can only be used for one of dali, data or dlls or spills.  An error will be reported if a plane is used for more than one purpose.  This prevents ECL queries having access to dali or dlls, (for reading or corruption).

Bare-metal compatible storage planes are similar, and are generally derived from the existing deployment.  They'll be documented later.

How the simple modes map onto the storage planes
------------------------------------------------

If no planes are mentioned for a specific class, then the following plane is implicitly created for the class::

  name: hpcc-<class>-plane
  prefix: /var/lib/HPCCSystems/hpcc<class>
  pvc: storage.<class>Storage.pvc

If no pvc was defined then an implicit pvc will be used.

Notes
=====
I suggest replication is only supported if explicitly defined using the storage planes, or if it is deduced from the group information on a bare metal system.

In the future we may want to restrict which storage planes
I suggest we deprecate the following options:
global.defaultDataPath
global.defaultMirrorPath
